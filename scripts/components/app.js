System.register(['angular2/core', './prism', './slide', './slides'], function(exports_1, context_1) {
    "use strict";
    var __moduleName = context_1 && context_1.id;
    var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
        var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
        if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
        else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
        return c > 3 && r && Object.defineProperty(target, key, r), r;
    };
    var __metadata = (this && this.__metadata) || function (k, v) {
        if (typeof Reflect === "object" && typeof Reflect.metadata === "function") return Reflect.metadata(k, v);
    };
    var core_1, prism_1, slide_1, slides_1;
    var AppComponent;
    return {
        setters:[
            function (core_1_1) {
                core_1 = core_1_1;
            },
            function (prism_1_1) {
                prism_1 = prism_1_1;
            },
            function (slide_1_1) {
                slide_1 = slide_1_1;
            },
            function (slides_1_1) {
                slides_1 = slides_1_1;
            }],
        execute: function() {
            AppComponent = (function () {
                function AppComponent() {
                }
                AppComponent = __decorate([
                    core_1.Component({
                        directives: [prism_1.PrismComponent, slide_1.SlideComponent, slides_1.SlidesComponent],
                        selector: 'wac-talk',
                        template: "\n        <slides>\n            <slide>\n                <h1 class=\"center\">Non Audio Signal Processing</h1>\n                <span class=\"center\">or</span>\n                <h2 class=\"center\">What else can we do<br>with the Web Audio API?</h2>\n                <h3 class=\"center\">\n                    <a href=\"https://chrisguttandin.github.io/web-audio-conference-2016\">chrisguttandin.github.io/web-audio-conference-2016</a>\n                </h3>\n            </slide>\n            <slide>\n                <h2>About me</h2>\n                <h3>Christoph Guttandin</h3>\n                <ul>\n                    <li>based in Berlin</li>\n                    <li>self employed at Media Codings</li>\n                    <li>develops a browser based DJ mixer called <a href=\"https://shffl.mx\">Shffl.mx</a></li>\n                    <li>usually named chrisguttandin at <a href=\"https://web-audio-slackin.herokuapp.com\">Slack</a>, <a href=\"https://github.com/chrisguttandin\">Github</a>, <a href=\"https://www.npmjs.com/~chrisguttandin\">NPM</a>, ...</li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>Agenda</h2>\n                <ul>\n                    <li>Audio Fingerprinting with audfprint</li>\n                    <li>Non Audio Signal Processing</li>\n                    <li>Bonus track: webaudio-serial-tx</li>\n                    <li>Bonus track: doppler</li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>Audio Fingerprinting</h2>\n                <ul>\n                    <li>retrieve (a) unique value(s) from an audio signal</li>\n                    <li>match and query audio signals</li>\n                    <li>open source implementations: <a href=\"https://acoustid.org\">AcousticID</a>, <a href=\"https://github.com/dpwe/audfprint\">audfprint</a>, <a href=\"http://echoprint.me/\">Echoprint</a>, <a href=\"http://panako.be/\">Panako</a></li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>audfprint</h2>\n                <ul>\n                    <li>uses landmark based fingerprinting</li>\n                    <li>used by the <a href=\"https://archive.org/post/1027794/new-music-analysis-files\">Internet Archive</a></li>\n                    <li>open sourced in Python</li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>audfprint's algorithm</h2>\n                <ul>\n                    <li>downsample audio to 11025 Hz</li>\n                    <li>downmix audio to mono</li>\n                    <li>apply the FFT each 256 samples</li>\n                    <li>find the largest magnitude</li>\n                    <li>apply a gate</li>\n                    <li>...</li>\n                    <li>apply an IIR filter</li>\n                    <li>... and much more</li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>Downsampling</h2>\n                <ul>\n                    <li>can be done easily</li>\n                    <li>each browser uses a different algorithm</li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>Downsampling</h2>\n                <prism language=\"javascript\">var downsampleContext = new OfflineAudioContext(\n        anyValidNumber,\n        anyValidNumber,\n        11025\n    );\n\ndownsampleContext.decodeAudioData(arrayBuffer);\n// will resolve with the downsampled audioBuffer</prism>\n            </slide>\n            <slide>\n                <h2>Downmixing</h2>\n                <ul>\n                    <li>works as well</li>\n                    <li>specified for common cases by the <a href=\"https://webaudio.github.io/web-audio-api/#down-mix\">API</a></li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>Downmixing</h2>\n                <prism language=\"javascript\">var downmixContext = new OfflineAudioContext(\n        1,\n        audioBuffer.length,\n        11025\n    );\n\nvar bufferSource = downmixContext.createBufferSource();\n\nbufferSource.buffer = audioBuffer;\nbufferSource.connect(downmixContext.destination);\nbufferSource.start();\n\ndownmixContext.startRendering();\n// will resolve with the downmixed audioBuffer</prism>\n            </slide>\n            <slide>\n                <h2>Apply FFT</h2>\n                <ul>\n                    <li>will not work</li>\n                    <li>the AnalyserNode is only designed to be used for real time usage</li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>Apply FFT</h2>\n                <prism language=\"javascript\">var analyser = offlineAudioContext.createAnalyser();\nvar buffer = new Float32Array(analyser.fftSize);\nvar scriptProcessor = offlineAudioContext.createScriptProcessor();\n\nscriptProcessor.onaudioprocess = () => {\n    analyser.getFloatFrequencyData(buffer);\n    // CAUTION: buffer will contain random data\n};\n\nanyNodeThatOutputsSound\n    .connect(analyser)\n    .connect(scriptProcessor)\n    .connect(offlineAudioContext.destination);\n\nofflineAudioContext.startRendering();</prism>\n            </slide>\n            <slide>\n                <h2>Apply FFT</h2>\n                <ul>\n                    <li>use <a href=\"https://chinpen.net/webaudiofftperf/\">WebAudio FFT Performance Test</a> to pick the fastest FFT library for your needs</li>\n                    <li>increased performance by 400% for me</li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>Find Maximum</h2>\n                <ul>\n                    <li>no native support</li>\n                    <li>ScriptProcessorNode does not fire each onaudioprocess event in <a href=\"https://github.com/chrisguttandin/standardized-audio-context/blob/master/test/expectation/chrome/current/offline-audio-context-constructor.js#L65\">Chrome</a>, <a href=\"https://github.com/chrisguttandin/standardized-audio-context/blob/master/test/expectation/opera/offline-audio-context-constructor.js#L65\">Opera</a> & <a href=\"https://github.com/chrisguttandin/standardized-audio-context/blob/master/test/expectation/safari/offline-audio-context-constructor.js#L65\">Safari</a></li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>Apply Gate</h2>\n                <ul>\n                    <li>no native support (yet)</li>\n                    <li>ScriptProcessorNode does not fire each onaudioprocess event</li>\n                    <li>ScriptProcessorNode does not have any output in all browsers</li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>Apply IIR filter</h2>\n                <ul>\n                    <li>works now in Chrome & Opera</li>\n                    <li>can't be reliably reimplemted</li>\n                    <li>10 times faster</li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>Good parts</h2>\n                <ul>\n                    <li>runs possibly faster because it's natively implemented</li>\n                    <li>it is already implemented</li>\n                    <li>AudioWorklets will solve all current problems</li>\n                    <li>suspend()/resume() allow the usage as a stream</li>\n                    <li>values from -4294967296 to 4294967296 are supported</li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>Not so good parts</h2>\n                <ul>\n                    <li>current state is broken</li>\n                    <li>no worker support</li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>Bonus track: <a href=\"https://github.com/substack/webaudio-serial-tx\">webaudio-serial-tx</a></h2>\n                <ul>\n                    <li>sends serial data via the audio output</li>\n                </ul>\n            </slide>\n            <slide>\n                <h2>Bonus track: <a href=\"https://danielrapp.github.io/doppler/\">doppler</a></h2>\n                <ul>\n                    <li>detecting motion by playing frequencies above the audible range and analyzing their response</li>\n                </ul>\n            </slide>\n            <slide>\n                <h1 class=\"center\">To a man with a hammer,<br>everything looks like a nail.</h1>\n            </slide>\n            <slide>\n                <h1 class=\"center\">To a developer with<br>the Web Audio API,<br>everything looks like<br>an audio graph.</h1>\n            </slide>\n            <slide>\n                <h2>Thank you</h2>\n                <h3><a href=\"https://web-audio-slackin.herokuapp.com\">Slack Channel (web-audio-slackin.herokuapp.com)</a></h3>\n                <h3><a href=\"https://chrisguttandin.github.io/web-audio-conference-2016\">Slides (chrisguttandin.github.io/web-audio-conference-2016)</a></h3>\n                <h3><a href=\"http://webaudio.berlin\">Berlin Web Audio Meetup (webaudio.berlin)</a></h3>\n            </slide>\n        </slides>\n    "
                    }), 
                    __metadata('design:paramtypes', [])
                ], AppComponent);
                return AppComponent;
            }());
            exports_1("AppComponent", AppComponent);
        }
    }
});
//# sourceMappingURL=app.js.map